{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:07.276475Z",
          "iopub.status.busy": "2025-07-20T19:08:07.275703Z",
          "iopub.status.idle": "2025-07-20T19:08:08.850453Z",
          "shell.execute_reply": "2025-07-20T19:08:08.849816Z",
          "shell.execute_reply.started": "2025-07-20T19:08:07.276434Z"
        },
        "id": "Ft9BZZFSTb5h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split\n",
        "from time import perf_counter\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPanfTXDQSE9",
        "outputId": "17982ce9-b0c6-44ce-a843-6d5ecd6176fa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:08.852620Z",
          "iopub.status.busy": "2025-07-20T19:08:08.851876Z",
          "iopub.status.idle": "2025-07-20T19:08:12.012235Z",
          "shell.execute_reply": "2025-07-20T19:08:12.011469Z",
          "shell.execute_reply.started": "2025-07-20T19:08:08.852578Z"
        },
        "id": "fuCFzkM8XH8S",
        "outputId": "b847a80e-dfa6-439e-80f9-c4cf2f20cfa7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install colour-demosaicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvvojMhWAT-B"
      },
      "outputs": [],
      "source": [
        "! rm -rf Restorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:12.013609Z",
          "iopub.status.busy": "2025-07-20T19:08:12.013340Z",
          "iopub.status.idle": "2025-07-20T19:08:12.141972Z",
          "shell.execute_reply": "2025-07-20T19:08:12.141218Z",
          "shell.execute_reply.started": "2025-07-20T19:08:12.013569Z"
        },
        "id": "MoDlx-CATiib",
        "outputId": "10b08b49-b0bf-44e2-e69f-cbe5d7ca6a34",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/rymuelle/Restorer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:12.144175Z",
          "iopub.status.busy": "2025-07-20T19:08:12.143916Z",
          "iopub.status.idle": "2025-07-20T19:08:20.930194Z",
          "shell.execute_reply": "2025-07-20T19:08:20.929116Z",
          "shell.execute_reply.started": "2025-07-20T19:08:12.144151Z"
        },
        "id": "AkFs7KYITyY_",
        "outputId": "1aa71e12-4a31-454d-c969-105c8787aa69",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! pip install Restorer/[losses]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:20.931660Z",
          "iopub.status.busy": "2025-07-20T19:08:20.931333Z",
          "iopub.status.idle": "2025-07-20T19:08:24.008261Z",
          "shell.execute_reply": "2025-07-20T19:08:24.007448Z",
          "shell.execute_reply.started": "2025-07-20T19:08:20.931625Z"
        },
        "id": "TNYD3amRbYRl",
        "outputId": "fccc6afa-77d0-4a62-a41a-a400c87c8a8c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJRt3rwVxhkV",
        "outputId": "7a763660-1c5f-4d31-e05e-654d12c30906"
      },
      "outputs": [],
      "source": [
        "!pip install kornia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:24.009471Z",
          "iopub.status.busy": "2025-07-20T19:08:24.009238Z",
          "iopub.status.idle": "2025-07-20T19:08:26.659339Z",
          "shell.execute_reply": "2025-07-20T19:08:26.658542Z",
          "shell.execute_reply.started": "2025-07-20T19:08:24.009448Z"
        },
        "id": "bzEV3u4waGhh",
        "outputId": "13000477-e52c-470d-ab00-9883d1ba3160",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from Restorer.Restorer import Restorer, AddPixelShuffle\n",
        "from Restorer.utils import numpy_pixel_shuffle, numpy_pixel_unshuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:26.660779Z",
          "iopub.status.busy": "2025-07-20T19:08:26.660501Z",
          "iopub.status.idle": "2025-07-20T19:08:27.623064Z",
          "shell.execute_reply": "2025-07-20T19:08:27.622307Z",
          "shell.execute_reply.started": "2025-07-20T19:08:26.660756Z"
        },
        "id": "P1vIRZdwXPKk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from colour_demosaicing import mosaicing_CFA_Bayer, demosaicing_CFA_Bayer_Malvar2004\n",
        "from torchvision.transforms import ToTensor\n",
        "import optuna\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:27.624892Z",
          "iopub.status.busy": "2025-07-20T19:08:27.623909Z",
          "iopub.status.idle": "2025-07-20T19:08:27.627943Z",
          "shell.execute_reply": "2025-07-20T19:08:27.627350Z",
          "shell.execute_reply.started": "2025-07-20T19:08:27.624869Z"
        },
        "id": "u5LcZ-zFT2Fu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Path to onsight\n",
        "checkpoint_path = '/content/drive/MyDrive/Onsight/Checkpoints'\n",
        "model_path = '/content/drive/MyDrive/Onsight/Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:27.628949Z",
          "iopub.status.busy": "2025-07-20T19:08:27.628681Z",
          "iopub.status.idle": "2025-07-20T19:08:27.642919Z",
          "shell.execute_reply": "2025-07-20T19:08:27.642238Z",
          "shell.execute_reply.started": "2025-07-20T19:08:27.628925Z"
        },
        "id": "DgNMPVdPVCtn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5SgS31o72sR"
      },
      "outputs": [],
      "source": [
        "from RawRefinery.train.pretraining import Flickr8kDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:27.840299Z",
          "iopub.status.busy": "2025-07-20T19:08:27.839641Z",
          "iopub.status.idle": "2025-07-20T19:08:27.855352Z",
          "shell.execute_reply": "2025-07-20T19:08:27.854753Z",
          "shell.execute_reply.started": "2025-07-20T19:08:27.840276Z"
        },
        "id": "O9OT4cO1WDfO",
        "outputId": "b3f796f7-bb22-4b86-e397-8c06bdc39057",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset = Flickr8kDataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:27.867547Z",
          "iopub.status.busy": "2025-07-20T19:08:27.867350Z",
          "iopub.status.idle": "2025-07-20T19:08:27.895571Z",
          "shell.execute_reply": "2025-07-20T19:08:27.894968Z",
          "shell.execute_reply.started": "2025-07-20T19:08:27.867525Z"
        },
        "id": "WW7jabqVo0uv",
        "outputId": "fd0c63e5-a7ec-49fd-ab71-a22f7a5625e3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "rggb_tensor, image_tensor, target_image_tensor, conditioning_tensor = dataset[30]\n",
        "plt.subplots(2,2, figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(image_tensor.permute(1,2,0))\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(target_image_tensor.permute(1,2,0)/1.2)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(target_image_tensor.permute(1,2,0))\n",
        "\n",
        "\n",
        "\n",
        "conditioning_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:27.896342Z",
          "iopub.status.busy": "2025-07-20T19:08:27.896170Z",
          "iopub.status.idle": "2025-07-20T19:08:27.899643Z",
          "shell.execute_reply": "2025-07-20T19:08:27.898869Z",
          "shell.execute_reply.started": "2025-07-20T19:08:27.896328Z"
        },
        "id": "5arPGztefyd1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set up for Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:31.935989Z",
          "iopub.status.busy": "2025-07-20T19:08:31.935553Z",
          "iopub.status.idle": "2025-07-20T19:08:31.941517Z",
          "shell.execute_reply": "2025-07-20T19:08:31.940638Z",
          "shell.execute_reply.started": "2025-07-20T19:08:31.935964Z"
        },
        "id": "c3JSAolXdjp4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "weight_file_path = f'{checkpoint_path}/gain_model_v4.pt'\n",
        "\n",
        "\n",
        "from Restorer.Restorer import Restorer, AddPixelShuffle\n",
        "\n",
        "\n",
        "def make_model(width = 58, base_blocks = 2, dec_blocks=2, late_blocks=1, vit_blocks=0, expand_dims=2):\n",
        "\n",
        "  total_late_block = max(base_blocks+late_blocks-vit_blocks, 0)\n",
        "  enc_blks = [base_blocks, base_blocks, total_late_block, total_late_block]\n",
        "  dec_blks = [dec_blocks, dec_blocks, dec_blocks, dec_blocks]\n",
        "  vit_blks = [0, 0, vit_blocks, vit_blocks]\n",
        "  middle_blk_num = base_blocks+late_blocks*2\n",
        "  cond_output=32\n",
        "  cond_input = 4\n",
        "  drop_path = 0.0 #trial.suggest_float(\"drop_path\",0, 0.1, log=False)\n",
        "  drop_path_increment = 0.05 #trial.suggest_float(\"drop_path_increment\",0, 0.1, log=False)\n",
        "  model = Restorer\n",
        "  model = Restorer(in_channels=4, out_channels=3 * 2 ** 2, width=width, middle_blk_num=middle_blk_num,\n",
        "                    enc_blk_nums=enc_blks, vit_blk_nums=vit_blks, dec_blk_nums=dec_blks,\n",
        "                    cond_input = cond_input, cond_output=cond_output, expand_dims=expand_dims,\n",
        "                   drop_path=drop_path,drop_path_increment=drop_path_increment)\n",
        "  model = AddPixelShuffle(model)\n",
        "  return model\n",
        "#[FrozenTrial(number=0, state=1, values=[0.0010226645435831695, 2463.5001086660195],  params={'width': 80, 'expand_dims': 2, 'base_blocks': 1, 'dec_blks': 2, 'late_blocks': 0}, user_attrs={}, system_attrs={'fixed_params': {'width': 80, 'expand_dims': 2, 'base_blocks': 1, 'dec_blks': 2, 'late_blocks': 0}}, intermediate_values={}, distributions={'width': IntDistribution(high=90, log=False, low=30, step=1), 'expand_dims': IntDistribution(high=4, log=False, low=1, step=1), 'base_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dec_blks': IntDistribution(high=3, log=False, low=1, step=1), 'late_blocks': IntDistribution(high=5, log=False, low=0, step=1)}, trial_id=1, value=None),\n",
        "\n",
        "def load_model(device):\n",
        "    #[FrozenTrial(number=4,  params={'width': 33, 'expand_dims': 2, 'base_blocks': 1, 'dec_blks': 2, 'late_blocks': 0}, user_attrs={}, system_attrs={'NSGAIISampler:generation': 0}, intermediate_values={}, distributions={'width': IntDistribution(high=90, log=False, low=30, step=1), 'expand_dims': IntDistribution(high=4, log=False, low=1, step=1), 'base_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dec_blks': IntDistribution(high=3, log=False, low=1, step=1), 'late_blocks': IntDistribution(high=5, log=False, low=0, step=1)}, trial_id=5, value=None),\n",
        "    #FrozenTrial(number=12, state=1, values=[0.0012007935130358552, 574.8597779699994],params={'width': 90, 'expand_dims': 4, 'base_blocks': 1, 'dec_blks': 1, 'late_blocks': 0}, user_attrs={}, system_attrs={'NSGAIISampler:generation': 0}, intermediate_values={}, distributions={'width': IntDistribution(high=90, log=False, low=30, step=1), 'expand_dims': IntDistribution(high=4, log=False, low=1, step=1), 'base_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dec_blks': IntDistribution(high=3, log=False, low=1, step=1), 'late_blocks': IntDistribution(high=5, log=False, low=0, step=1)}, trial_id=13, value=None),\n",
        "    width = 58\n",
        "    expand_dims = 2\n",
        "    base_blocks = 2\n",
        "    dec_blocks = 2\n",
        "    late_blocks = 1\n",
        "\n",
        "    # Model, loss, optimizer\n",
        "    model = make_model(width=width, base_blocks=base_blocks, late_blocks=late_blocks, expand_dims=expand_dims, dec_blocks=dec_blocks)\n",
        "    model = model.to(device)\n",
        "    state_dict = torch.load(weight_file_path,map_location=torch.device('cpu'))\n",
        "\n",
        "    new_dict = {}\n",
        "    for key, value in torch.load(weight_file_path,map_location=torch.device('cpu')).items():\n",
        "        if 'conditioning_gen' not in key:\n",
        "            new_dict[key] = value\n",
        "    model.load_state_dict(new_dict, strict=False)\n",
        "    model.to(device)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaQhR7RzddnG"
      },
      "outputs": [],
      "source": [
        "from Restorer.CombinedPerceptualLoss import CombinedPerceptualLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4vk4_f_z22i",
        "outputId": "32c3879a-7532-4ef3-e27a-0ff967c20591"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "val_split=0.1\n",
        "test_split=0.1\n",
        "val_size = int(len(dataset) * val_split)\n",
        "test_size = int(len(dataset) * test_split)\n",
        "batch_size=4\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "with torch.no_grad():\n",
        "  for rggb_tensor, image_tensor, target_image_tensor, conditioning_tensor in train_loader:\n",
        "        target_image_tensor = target_image_tensor.to(device).float()\n",
        "\n",
        "\n",
        "        # demosaic_noise = demosaic_noise.to(device).float()\n",
        "        # demosaic_clean = demosaic_clean.to(device).float()\n",
        "        # rggb_img = rggb_img.to(device).float()\n",
        "        # noise_level = noise_level.to(device).float()/0.06\n",
        "        break\n",
        "conditioning_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hhYthaDkEclQ",
        "outputId": "8b2b0996-b603-4841-8763-d04bb93cd0cc"
      },
      "outputs": [],
      "source": [
        "plt.imshow(target_image_tensor[1].permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:32.536980Z",
          "iopub.status.busy": "2025-07-20T19:08:32.536385Z",
          "iopub.status.idle": "2025-07-20T19:08:32.551593Z",
          "shell.execute_reply": "2025-07-20T19:08:32.550840Z",
          "shell.execute_reply.started": "2025-07-20T19:08:32.536955Z"
        },
        "id": "jvM4g0fIezsG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    best_model_path = os.path.join(checkpoint_path, f'grain_tune_{trial.number}.pt')\n",
        "    print(best_model_path)\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    # Hyperparameters\n",
        "    width = 58\n",
        "    expand_dims = 2\n",
        "    base_blocks = 2\n",
        "    dec_blocks = 2\n",
        "    vit_blocks = 2\n",
        "    late_blocks = 1\n",
        "    #late_blocks = 0\n",
        "    #max_val_epoch = trial.suggest_int(\"max_val_epoch\", 1, 20)\n",
        "    max_val_epoch = 5\n",
        "    drop_path = 0.0 #trial.suggest_float(\"drop_path\",0, 0.1, log=False)\n",
        "    drop_path_increment = 0.05 #trial.suggest_float(\"drop_path_increment\",0, 0.1, log=False)\n",
        "    l2_reg =  0 #trial.suggest_float(\"l2_reg\", 1e-8, 1e-3, log=True)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # lr = 7e-4\n",
        "    clip = 8e-3#trial.suggest_float(\"clip\", 1e-4, 1e1, log=True)\n",
        "\n",
        "    batch_size = 2\n",
        "    lr = batch_size * lr / 2\n",
        "    num_epochs = 101\n",
        "    val_split = 0.2\n",
        "    test_split = 0.6\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Running on device: {device}\")\n",
        "\n",
        "    # Split dataset into train and val\n",
        "    val_size = int(len(dataset) * val_split)\n",
        "    test_size = int(len(dataset) * test_split)\n",
        "    train_size = len(dataset) - val_size - test_size\n",
        "    torch.manual_seed(42)  # For reproducibility\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    model = load_model(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr*0.01)\n",
        "    #loss_func = CombinedPerceptualLoss(mse=1)\n",
        "    loss_func = CombinedPerceptualLoss(mse=1*0.5, ssim=0.2, vgg=0.0015)\n",
        "\n",
        "    loss_func = loss_func.to(device)\n",
        "    loss_func.loss_modules['vgg'] = loss_func.loss_modules['vgg'].to(device)\n",
        "    start = perf_counter()\n",
        "\n",
        "    print(f\"\\n Trial {trial.number} parameters:\")\n",
        "    print(f\"  width: {width}\")\n",
        "    print(f\"  expand_dims: {expand_dims}\")\n",
        "    print(f\"  base_blocks: {base_blocks}\")\n",
        "    print(f\"  late_blocks: {late_blocks}\")\n",
        "    print(f\"  max_val_epoch: {max_val_epoch}\")\n",
        "    print(f\"  dec_blocks: {dec_blocks}\")\n",
        "    print(f\"  drop_path: {drop_path}\")\n",
        "    print(f\"  drop_path_increment: {drop_path_increment}\")\n",
        "    print(f\"  l2_reg: {l2_reg}\")\n",
        "    print(f\"  lr: {lr:.2e}\")\n",
        "    print(f\"  clip: {clip:.2e}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      # train\n",
        "      model.train()\n",
        "      print(epoch)\n",
        "      n_images = 0\n",
        "      total_loss = 0\n",
        "      for rggb_tensor, image_tensor, target_image_tensor, conditioning_tensor in train_loader:\n",
        "            rggb_tensor = rggb_tensor.to(device).float()\n",
        "            target_image_tensor = target_image_tensor.to(device).float()\n",
        "            conditioning_tensor = conditioning_tensor.to(device).float()\n",
        "\n",
        "            pred = model(rggb_tensor, conditioning_tensor)\n",
        "\n",
        "            # Scale to 0 to 1\n",
        "            # mins = torch.amin(target_image_tensor, dim=(1,2,3), keepdim=True)\n",
        "            # maxs = torch.amax(target_image_tensor, dim=(1,2,3), keepdim=True)\n",
        "            # target_image_tensor -= mins\n",
        "            # target_image_tensor /= maxs-mins\n",
        "            # pred -= mins\n",
        "            # pred /= maxs-mins\n",
        "\n",
        "            loss = loss_func(pred, target_image_tensor)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "            optimizer.step()\n",
        "            n_images += pred.size(0)\n",
        "            total_loss += loss.item() * pred.size(0)\n",
        "\n",
        "      scheduler.step()\n",
        "      # print current learning rate\n",
        "      lr = optimizer.param_groups[0]['lr']\n",
        "      print(f'total_loss: {total_loss/n_images:.2e} lr: {lr:.2e}')\n",
        "\n",
        "      if epoch % 5 == 0:\n",
        "          start_val = perf_counter()\n",
        "          # Evaluate on validation set\n",
        "          model.eval()\n",
        "          val_loss = 0\n",
        "          n_val = 0\n",
        "          with torch.no_grad():\n",
        "            for rggb_tensor, image_tensor, target_image_tensor, conditioning_tensor in train_loader:\n",
        "                  rggb_tensor = rggb_tensor.to(device).float()\n",
        "                  target_image_tensor = target_image_tensor.to(device).float()\n",
        "                  conditioning_tensor = conditioning_tensor.to(device).float()\n",
        "\n",
        "                  pred = model(rggb_tensor, conditioning_tensor)\n",
        "\n",
        "                  # Scale to 0 to 1\n",
        "                  # mins = torch.amin(target_image_tensor, dim=(1,2,3), keepdim=True)\n",
        "                  # maxs = torch.amax(target_image_tensor, dim=(1,2,3), keepdim=True)\n",
        "                  # target_image_tensor -= mins\n",
        "                  # target_image_tensor /= maxs-mins\n",
        "                  # pred -= mins\n",
        "                  # pred /= maxs-mins\n",
        "\n",
        "                  val_loss += loss.item() * pred.size(0)\n",
        "                  n_val += pred.size(0)\n",
        "\n",
        "          end_val = perf_counter()\n",
        "          avg_val_loss = val_loss / n_val\n",
        "          print(f'{avg_val_loss:.2e}')\n",
        "          trial.report(avg_val_loss, epoch)\n",
        "          torch.save(model.state_dict(), best_model_path)\n",
        "          if avg_val_loss < best_val_loss:\n",
        "              best_val_loss = avg_val_loss\n",
        "              torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "          if epoch > 1 and trial.should_prune():\n",
        "              raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # torch.save(model.state_dict(), best_model_path)\n",
        "    run_time = perf_counter() - start\n",
        "\n",
        "    # Clean up\n",
        "    del model, image, rggb_img, noise_level, pred, loss\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"Trial {trial.number} finished in {run_time:.2f}s with val_loss: {avg_val_loss:.4e}\")\n",
        "    return avg_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:32.990469Z",
          "iopub.status.busy": "2025-07-20T19:08:32.990198Z",
          "iopub.status.idle": "2025-07-20T19:08:33.344631Z",
          "shell.execute_reply": "2025-07-20T19:08:33.343861Z",
          "shell.execute_reply.started": "2025-07-20T19:08:32.990450Z"
        },
        "id": "IPxbN2vaezpU",
        "outputId": "6ebd992b-b910-47b5-eefd-0d2a48b72e78",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.storages import JournalStorage, JournalFileStorage  # Optional alternative to SQLite\n",
        "import os\n",
        "\n",
        "\n",
        "# Define a persistent SQLite storage\n",
        "study_name = \"grain_tune\"\n",
        "# Use a Google Drive path\n",
        "storage_path = f\"sqlite:///{checkpoint_path}/{study_name}.db\"\n",
        "\n",
        "# Create or load the study\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "\n",
        "    study_name=study_name,\n",
        "    storage=storage_path,\n",
        "    load_if_exists=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-20T19:08:33.349970Z",
          "iopub.status.busy": "2025-07-20T19:08:33.349762Z",
          "iopub.status.idle": "2025-07-20T19:08:33.369556Z",
          "shell.execute_reply": "2025-07-20T19:08:33.368876Z",
          "shell.execute_reply.started": "2025-07-20T19:08:33.349953Z"
        },
        "id": "IBgKmUI622nT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "study.enqueue_trial({\"lr\": 7e-4})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "execution_failed": "2025-07-20T23:36:14.118Z",
          "iopub.execute_input": "2025-07-20T19:08:38.976004Z",
          "iopub.status.busy": "2025-07-20T19:08:38.975242Z"
        },
        "id": "9fj6fn0RlPL1",
        "outputId": "9fcad82f-81ae-4ba9-a8c3-dec06c162aae",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=20, timeout=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "execution_failed": "2025-07-19T14:55:53.299Z"
        },
        "id": "-7KE3ErdezU7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from plotly.io import show\n",
        "fig = optuna.visualization.plot_optimization_history(study)\n",
        "show(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfTyEDcONi5P",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 623289,
          "isSourceIdPinned": false,
          "sourceId": 1111676,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
