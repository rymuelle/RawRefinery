{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from RawHandler.utils import linear_to_srgb, linear_to_srgb_torch\n",
    "from RawRefinery.train.RawImagePatchDataset import RawImagePatchDataset\n",
    "from Restorer.CombinedPerceptualLoss import VGGPerceptualLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_path = '../weights/train_on_raws_trained_on_lin_rec2020_MS_SSIM_L1_VGG_GAN_initialize_ddfapd_removed_GAN.pt'\n",
    "input_model_weight_path = '../weights/train_on_raws_trained_on_lin_rec2020_MS_SSIM_L1_VGG_GAN_initialize_ddfapd.pt'\n",
    "\n",
    "GAN_weight_path ='../weights/patchGAN_noise_conditioned.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b93f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RawImagePatchDataset('align.csv', patch_size=256, colorspace='lin_rec2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebea9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dataset[60]\n",
    "\n",
    "plt.subplots(1, 3)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(linear_to_srgb(output['gt'].permute(1, 2, 0)))\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(linear_to_srgb(output['noisy'].permute(1, 2, 0)))\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(linear_to_srgb(output['noisy'].permute(1, 2, 0))-linear_to_srgb(output['gt'].permute(1, 2, 0))+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "val_split = 0.2\n",
    "test_split = 0.2\n",
    "\n",
    "# Split dataset into train and val\n",
    "val_size = int(len(dataset) * val_split)\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa55a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "from RawRefinery.train.load_model import load_model\n",
    "\n",
    "weight_file_path = input_model_weight_path\n",
    "device = 'mps'\n",
    "model = load_model(device, weight_file_path)\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3eed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4/4\n",
    "clip = 8e-3\n",
    "l2_reg = 0\n",
    "num_epochs = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr*0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, base_channels=64):\n",
    "        super().__init__()\n",
    "        def block(in_ch, out_ch, stride=2):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 4, stride, 1),\n",
    "                nn.InstanceNorm2d(out_ch, affine=True),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            block(in_channels, base_channels),\n",
    "            block(base_channels, base_channels * 2),\n",
    "            block(base_channels * 2, base_channels * 4),\n",
    "            block(base_channels * 4, base_channels * 8),\n",
    "            nn.Conv2d(base_channels * 8, 1, 4, padding=1) \n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, m):\n",
    "        \"\"\"\n",
    "        Applies initial weights to all convolutional and normalization layers.\n",
    "        \"\"\"\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('InstanceNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3365ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = PatchDiscriminator(in_channels=6)\n",
    "state_dict = torch.load(GAN_weight_path, map_location=torch.device('cpu'))\n",
    "# disc.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "disc = disc.to(device)\n",
    "\n",
    "\n",
    "disclr = lr\n",
    "disc_optimizer = torch.optim.Adam(disc.parameters(), lr=disclr, weight_decay=l2_reg)\n",
    "disc_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(disc_optimizer, T_max=num_epochs, eta_min=disclr*0.01)\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_msssim import ms_ssim\n",
    "\n",
    "def gaussian_kernel(kernel_size=11, sigma=1.5, channels=3):\n",
    "    \"\"\"Creates a 2D Gaussian kernel for applying to each channel.\"\"\"\n",
    "    coords = torch.arange(kernel_size).float() - kernel_size // 2\n",
    "    g = torch.exp(-(coords**2) / (2 * sigma**2))\n",
    "    g = g / g.sum()\n",
    "    kernel_2d = torch.outer(g, g)\n",
    "    kernel_2d = kernel_2d / kernel_2d.sum()\n",
    "    kernel_2d = kernel_2d.expand(channels, 1, kernel_size, kernel_size).contiguous()\n",
    "    return kernel_2d\n",
    "\n",
    "def gaussian_filter(x, kernel):\n",
    "    \"\"\"Applies Gaussian filter to each channel using depthwise convolution.\"\"\"\n",
    "    channels = x.shape[1]\n",
    "    return F.conv2d(x, kernel, padding=kernel.shape[-1] // 2, groups=channels)\n",
    "    \n",
    "\n",
    "\n",
    "class MS_SSIM_L1_VGG_Loss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.84, vgg_weight = .001, kernel_size=11, sigma=1.5, device=device):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.vgg_weight = vgg_weight\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.vgg_loss = VGGPerceptualLoss(apply_gamma_curve=False)\n",
    "        self.vgg_loss = self.vgg_loss.to(device)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "\n",
    "\n",
    "        # # Gaussian-weighted L1 loss\n",
    "        abs_error = torch.abs(pred - target)\n",
    "        # gauss = gaussian_kernel(kernel_size=self.kernel_size, sigma=self.sigma, channels=pred.shape[1]).to(pred.device)\n",
    "        # weighted_l1 = gaussian_filter(abs_error, gauss)\n",
    "\n",
    "        # # Mean over pixels and batch\n",
    "        weighted_l1_loss = abs_error.mean()\n",
    "        \n",
    "        # VGG Loss \n",
    "        pred_gamma = linear_to_srgb_torch(pred)\n",
    "        target_gamma = linear_to_srgb_torch(target)\n",
    "\n",
    "        vgg_loss = self.vgg_loss(pred, target_gamma)\n",
    "\n",
    "        # MS-SSIM term (averaged over batch)\n",
    "        ms_ssim_loss = 1 - ms_ssim(pred_gamma, target_gamma, data_range=1.0, size_average=True)\n",
    "        \n",
    "        return self.alpha * ms_ssim_loss + (1 - self.alpha) * weighted_l1_loss + vgg_loss*self.vgg_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = MS_SSIM_L1_VGG_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad528880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    print(epoch)\n",
    "    n_images = 0\n",
    "    total_loss = 0\n",
    "    D_loss = 0\n",
    "    loss_disc_total = 0\n",
    "    for data in train_loader:\n",
    "        input = data['noisy_rggb_tensor'].to(device)\n",
    "        conditioning = data['conditioning'].to(device)\n",
    "        gt = data['gt'].to(device)\n",
    "        noisy = data['noisy'].to(device)\n",
    "\n",
    "        # --- Train Disc. ---\n",
    "        fake_output = model(input, conditioning).detach()\n",
    "        fake_output = noisy + fake_output\n",
    "\n",
    "        gt_d = torch.cat([noisy, gt], dim=1)\n",
    "        pred_real = disc(gt_d)\n",
    "        fake_output_d = torch.cat([noisy, fake_output], dim=1)\n",
    "        pred_fake = disc(fake_output_d)\n",
    "\n",
    "        loss_disc = 0.5 * (adversarial_loss(pred_real, torch.ones_like(pred_real)) +\n",
    "                        adversarial_loss(pred_fake, torch.zeros_like(pred_fake)))\n",
    "        \n",
    "        disc_optimizer.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        # --- Train model ---\n",
    "        pred = model(input, conditioning)\n",
    "        pred = noisy + pred\n",
    "\n",
    "        loss = loss_func(pred, gt)\n",
    "        pred_d = torch.cat([noisy, pred], dim=1)\n",
    "        pred_fake = disc(pred_d)\n",
    "        \n",
    "        loss_adv = adversarial_loss(pred_fake, torch.ones_like(pred_fake)) * 0.005 * 0\n",
    "        loss += loss_adv \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        n_images += gt.size(0)\n",
    "        # if n_images > 100: break\n",
    "        total_loss += loss.item() * gt.size(0)\n",
    "        D_loss += loss_adv.item() * gt.size(0)\n",
    "        loss_disc_total+=loss_disc.item() * gt.size(0)\n",
    "\n",
    "    torch.save(model.state_dict(), model_weight_path)\n",
    "    torch.save(disc.state_dict(), GAN_weight_path)\n",
    "\n",
    "    scheduler.step()\n",
    "    disc_scheduler.step()\n",
    "\n",
    "    # # print current learning rate\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    # # print(f'total_loss: {total_loss/n_images:.2e}  disc. loss {D_loss/n_images:.2e}, lr: {lr:.2e}')\n",
    "    print(f'loss: {total_loss/n_images:.2e}  loss_adv: {D_loss/n_images:.2e}, loss_disc_total: {loss_disc_total/n_images:.2e} lr: {lr:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc851d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae814a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OnSight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
